{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7e8c0f7-f22c-4fc7-a65e-ddf111e37c01",
   "metadata": {},
   "source": [
    "## Data importation: importing data, handling missing data and customizing columns and values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ed96d2-5b96-4be9-aa08-6eb055467608",
   "metadata": {},
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82190b01-d31e-44dc-9847-45642f5a29a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba4a9cf-9d91-48c1-8c03-61e3f34e663e",
   "metadata": {},
   "source": [
    "Defining a global function with local functions created to clean each dataframe. This is useful to save time and standarize the cleaining process over all the dataframes. Mainly, the columns of interest were filtered to be included, some datatypes changed and some values as well, to improve understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04535503-9f66-427d-969b-160ae7d50aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpieza(y):\n",
    "\n",
    "    \"\"\"\n",
    "    Function created to clean dataframes (20) individually before concatenating them\n",
    "    Inside the function there are local ones created to perform the specific data cleaning actions\n",
    "    \"\"\"\n",
    "    \n",
    "    #Edit the formatting including the directory where you stored the data\n",
    "    año_df = f\"C:/Users/mirko/Desktop/EK/JyJ/artroplastia rodilla PAD/Egresos Hospitalarios/raw_data/Egresos_Hospitalarios_{y}.csv\"\n",
    "    df_limpio = pd.read_csv(año_df, encoding='ISO-8859-1', on_bad_lines='skip', sep = \";\", low_memory=False)\n",
    "    \n",
    "\n",
    "    def importacion(df):\n",
    "        df.columns = df.columns.str.strip()\n",
    "        df = df[[\"ID_PACIENTE\",\"SEXO\",\"EDAD_A_OS\",\"PREVISION\", \"PERTENENCIA_ESTABLECIMIENTO_SALUD\", \"GLOSA_ESTABLECIMIENTO_SALUD\",\n",
    "             \"DIAS_ESTADA\",\"CONDICION_EGRESO\",\"DIAG1\",\"GLOSA_DIAG1\"]].copy()\n",
    "        df.dropna(subset = [\"SEXO\",\"EDAD_A_OS\",\"PREVISION\", \"PERTENENCIA_ESTABLECIMIENTO_SALUD\",\n",
    "             \"DIAS_ESTADA\",\"CONDICION_EGRESO\",\"DIAG1\",\"GLOSA_DIAG1\"],inplace = True)\n",
    "        df[\"Año\"] = f\"{y}\"\n",
    "        df[\"Año\"] = pd.to_datetime(df[\"Año\"]).dt.year\n",
    "        df[\"SEXO\"] = df[\"SEXO\"].astype(str)\n",
    "        df[\"ID_PACIENTE\"] = df[\"ID_PACIENTE\"].astype(str)\n",
    "        df[\"PREVISION\"] = df[\"PREVISION\"].astype(str)\n",
    "        df[\"CONDICION_EGRESO\"] = df[\"CONDICION_EGRESO\"].astype(str)\n",
    "        return df\n",
    "\n",
    "    def tipo_col(df):\n",
    "        df[\"SEXO\"] = df[\"SEXO\"].astype(str)\n",
    "        df[\"ID_PACIENTE\"] = df[\"ID_PACIENTE\"].astype(str)\n",
    "        df[\"PREVISION\"] = df[\"PREVISION\"].astype(str)\n",
    "        df[\"CONDICION_EGRESO\"] = df[\"CONDICION_EGRESO\"].astype(str)\n",
    "        return df\n",
    "\n",
    "    def sexo(x):\n",
    "        if x == \"2\" or x == \"2\":\n",
    "            x = \"Mujer\"\n",
    "        elif x == \"1\" or x == \"1.0\":\n",
    "            x = \"Hombre\"\n",
    "        else:\n",
    "            x = \"Otro\"\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def prevision(x):\n",
    "        if x == \"1\" or x == \"1.0\":\n",
    "            x = \"Fonasa\"\n",
    "        elif x == \"2\" or x == \"2.0\":\n",
    "            x = \"Isapre\"\n",
    "        else:\n",
    "            x = \"Eliminar\"\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def condicion(x):\n",
    "        if x == \"1.0\" or x == \"1\":\n",
    "            x = \"Vivo\"\n",
    "        elif x == \"2.0\" or x == \"2\":\n",
    "            x = \"Muerto\"\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def pubpriv(x):\n",
    "       if x == \"Pertenecientes al Sistema Nacional de Servicios de Salud, SNSS\":\n",
    "           x = \"Publico\"\n",
    "       elif x == \"No Pertenecientes al Sistema Nacional de Servicios de Salud, SNSS\":\n",
    "            x = \"Privado\"\n",
    "        \n",
    "       return x\n",
    "\n",
    "    def col_transformation(data):\n",
    "        data[\"SEXO\"] = data[\"SEXO\"].apply(sexo)\n",
    "        data[\"PREVISION\"] = data[\"PREVISION\"].apply(prevision)\n",
    "        data[\"CONDICION_EGRESO\"] = data[\"CONDICION_EGRESO\"].apply(condicion)\n",
    "        data[\"PERTENENCIA_ESTABLECIMIENTO_SALUD\"] = data[\"PERTENENCIA_ESTABLECIMIENTO_SALUD\"].apply(pubpriv)\n",
    "        data = data[data['PREVISION'] != 'Eliminar']\n",
    "        data = data[data['SEXO'] != 'Otro']\n",
    "\n",
    "        return data\n",
    "\n",
    "    df_limpio = importacion(df_limpio)\n",
    "    df_limpio = tipo_col(df_limpio)\n",
    "    df_limpio = col_transformation(df_limpio)\n",
    "\n",
    "    return df_limpio\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cf5200-18b8-4c8e-8984-9690c9fe4275",
   "metadata": {},
   "source": [
    "Looping over the 20 dataframes to import, clean and store them dinamically. Again, this is more efficient than just applying the function over each dataframe separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dab7cbb9-b669-42e3-ba0b-72fe4b7877e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of file paths. Edit the formatting including the directory where you stored the data\n",
    "archivos = [fr\"C:\\Users\\mirko\\Desktop\\EK\\JyJ\\artroplastia rodilla PAD\\Egresos Hospitalarios\\raw_data\\Egresos_Hospitalarios_{año}.csv\" for año in range(2001, 2021)]\n",
    "\n",
    "# Initialize an empty dictionary to store the DataFrames\n",
    "dataframes = {}\n",
    "\n",
    "# Loop through the file paths and load each file into the dictionary\n",
    "for i, file in enumerate(archivos):\n",
    "    # Dynamically create a name for each DataFrame, e.g., \"df_1\", \"df_2\", etc.\n",
    "    dataframe_name = f\"df_{i+2001}\"\n",
    "    \n",
    "    # Load the CSV into a DataFrame and store it in the dictionary\n",
    "    dataframes[dataframe_name] = limpieza(f\"{i+2001}\")\n",
    "\n",
    "# Access DataFrames by their names\n",
    "# print(dataframes[\"df_2005\"].head())  # View the first few rows of the first DataFrame\n",
    "# print(dataframes[\"df_2007\"].info())  # View information about the second DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0e9857-422a-49fc-9046-b8ddc4b3d897",
   "metadata": {},
   "source": [
    "## Concatenate and export data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb59659-7aa9-4349-8196-3925177c9e19",
   "metadata": {},
   "source": [
    "With the raw dataframes imported and cleaned it is the moment to concatenate them and to delete missing data in the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb71b3a5-09ab-40e4-a363-3e6980ac83b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26340655, 11)\n"
     ]
    }
   ],
   "source": [
    "# Concatenar:\n",
    "combined_df = pd.concat(dataframes.values(), ignore_index=True)\n",
    "print(combined_df.shape)\n",
    "\n",
    "# sin eliminar nulos: (26340664, 10)\n",
    "# eliminando nulos: (26340655, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4792c51-dbf3-4388-941d-b7c1d65100ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(\"Egresos_2001-2020.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b09be1f7-8209-4085-aec1-ccd4ad6bebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over the concatenated dataframe, some columns are changed to lighter data types to make faster and efficient the memory usage\n",
    "combined_df[\"SEXO\"] = combined_df[\"SEXO\"].astype(\"category\")\n",
    "combined_df[\"ID_PACIENTE\"] = combined_df[\"ID_PACIENTE\"].astype(\"category\")\n",
    "combined_df[\"PREVISION\"] = combined_df[\"PREVISION\"].astype(\"category\")\n",
    "combined_df[\"PERTENENCIA_ESTABLECIMIENTO_SALUD\"] = combined_df[\"PERTENENCIA_ESTABLECIMIENTO_SALUD\"].astype(\"category\")\n",
    "combined_df[\"DIAS_ESTADA\"] = combined_df[\"DIAS_ESTADA\"].astype(np.int32)\n",
    "combined_df[\"CONDICION_EGRESO\"] = combined_df[\"CONDICION_EGRESO\"].astype(\"category\")\n",
    "combined_df[\"EDAD_A_OS\"] = combined_df[\"EDAD_A_OS\"].astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e392290c-5646-4bb5-aa85-5715c07c07f9",
   "metadata": {},
   "source": [
    "The dataframe is transformed into a parquet file, which is lighter and easier to import into other notebooks or upload to Kaggle to share it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bfe8185-fc09-4e4b-bbcc-cb370a51afed",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_parquet('Egresos_2001-2020.parquet', index=False, compression=\"gzip\")  # Save as Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0303ce-651d-474a-ac8c-6f54579de2c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
